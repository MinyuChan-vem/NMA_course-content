{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinyuChan-vem/NMA_course-content/blob/main/HCP_emotion_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The HCP dataset comprises task-based fMRI from a large sample of human subjects. The NMA-curated dataset includes time series data that has been preprocessed and spatially-downsampled by aggregating within 360 regions of interest.\n",
        "\n",
        "In order to use this dataset, please electronically sign the HCP data use terms at ConnectomeDB. Instructions for this are on pp. 24-25 of the HCP Reference Manual.\n",
        "\n",
        "In this notebook, NMA provides code for downloading the data and doing some basic visualisation and processing.\n",
        "\n",
        "For a detailed description of the tasks have a look pages 45-54 of the HCP reference manual."
      ],
      "metadata": {
        "id": "YWiKbDJV1SvQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3b2LS-y8ya3R",
        "outputId": "e0e306ef-e91b-4be8-b25c-7ead9a3b504e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title Install dependencies\n",
        "!pip install nilearn --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gsRZbAWJzDqp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Figure settings\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
      ],
      "metadata": {
        "id": "2YrxECrIzU0y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The data shared for NMA projects is a subset of the full HCP dataset\n",
        "N_SUBJECTS = 100\n",
        "\n",
        "# The data have already been aggregated into ROIs from the Glasser parcellation\n",
        "N_PARCELS = 360\n",
        "\n",
        "# The acquisition parameters for all tasks were identical\n",
        "TR = 0.72  # Time resolution, in seconds\n",
        "\n",
        "# The parcels are matched across hemispheres with the same order\n",
        "HEMIS = [\"Right\", \"Left\"]\n",
        "\n",
        "# Each experiment was repeated twice in each subject\n",
        "RUNS   = ['LR','RL']\n",
        "N_RUNS = 2\n",
        "\n",
        "# There are 7 tasks. Each has a number of 'conditions'\n",
        "# TIP: look inside the data folders for more fine-graned conditions\n",
        "\n",
        "EXPERIMENTS = {\n",
        "    'MOTOR'      : {'cond':['lf','rf','lh','rh','t','cue']},\n",
        "    'WM'         : {'cond':['0bk_body','0bk_faces','0bk_places','0bk_tools','2bk_body','2bk_faces','2bk_places','2bk_tools']},\n",
        "    'EMOTION'    : {'cond':['fear','neut']},\n",
        "    'GAMBLING'   : {'cond':['loss','win']},\n",
        "    'LANGUAGE'   : {'cond':['math','story']},\n",
        "    'RELATIONAL' : {'cond':['match','relation']},\n",
        "    'SOCIAL'     : {'cond':['ment','rnd']}\n",
        "}"
      ],
      "metadata": {
        "id": "IdidiIdR00Yp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading data"
      ],
      "metadata": {
        "id": "szb0d-fS1imT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download data file\n",
        "import os, requests\n",
        "\n",
        "fname = \"hcp_task.tgz\"\n",
        "url = \"https://osf.io/2y3fw/download\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)"
      ],
      "metadata": {
        "id": "JUvfM5ra1lcB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The download cells will store the data in nested directories starting here:\n",
        "HCP_DIR = \"./hcp_task\"\n",
        "\n",
        "# importing the \"tarfile\" module\n",
        "import tarfile\n",
        "\n",
        "# open file\n",
        "with tarfile.open(fname) as tfile:\n",
        "  # extracting file\n",
        "  tfile.extractall('.')\n",
        "\n",
        "subjects = np.loadtxt(os.path.join(HCP_DIR, 'subjects_list.txt'), dtype='str')"
      ],
      "metadata": {
        "id": "JxhpLHRo1s04"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_ids(name):\n",
        "  \"\"\"Get the 1-based image indices for runs in a given experiment.\n",
        "\n",
        "    Args:\n",
        "      name (str) : Name of experiment (\"rest\" or name of task) to load\n",
        "    Returns:\n",
        "      run_ids (list of int) : Numeric ID for experiment image files\n",
        "\n",
        "  \"\"\"\n",
        "  run_ids = [\n",
        "             i for i, code in enumerate(BOLD_NAMES, 1) if name.upper() in code\n",
        "             ]\n",
        "  if not run_ids:\n",
        "    raise ValueError(f\"Found no data for '{name}'\")\n",
        "  return run_ids\n",
        "\n",
        "\n",
        "def load_timeseries(subject, name, dir,\n",
        "                    runs=None, concat=True, remove_mean=True):\n",
        "  \"\"\"Load timeseries data for a single subject.\n",
        "\n",
        "  Args:\n",
        "    subject (int): 0-based subject ID to load\n",
        "    name (str) : Name of experiment (\"rest\" or name of task) to load\n",
        "    dir (str) : data directory\n",
        "    run (None or int or list of ints): 0-based run(s) of the task to load,\n",
        "      or None to load all runs.\n",
        "    concat (bool) : If True, concatenate multiple runs in time\n",
        "    remove_mean (bool) : If True, subtract the parcel-wise mean\n",
        "\n",
        "  Returns\n",
        "    ts (n_parcel x n_tp array): Array of BOLD data values\n",
        "\n",
        "  \"\"\"\n",
        "  # Get the list relative 0-based index of runs to use\n",
        "  if runs is None:\n",
        "    runs = range(N_RUNS_REST) if name == \"rest\" else range(N_RUNS_TASK)\n",
        "  elif isinstance(runs, int):\n",
        "    runs = [runs]\n",
        "\n",
        "  # Get the first (1-based) run id for this experiment\n",
        "  offset = get_image_ids(name)[0]\n",
        "\n",
        "  # Load each run's data\n",
        "  bold_data = [\n",
        "               load_single_timeseries(subject,\n",
        "                                      offset + run,\n",
        "                                      dir,\n",
        "                                      remove_mean) for run in runs\n",
        "               ]\n",
        "\n",
        "  # Optionally concatenate in time\n",
        "  if concat:\n",
        "    bold_data = np.concatenate(bold_data, axis=-1)\n",
        "\n",
        "  return bold_data\n",
        "\n",
        "\n",
        "def load_single_timeseries(subject, bold_run, dir, remove_mean=True):\n",
        "  \"\"\"Load timeseries data for a single subject and single run.\n",
        "\n",
        "  Args:\n",
        "    subject (int): 0-based subject ID to load\n",
        "    bold_run (int): 1-based run index, across all tasks\n",
        "    dir (str) : data directory\n",
        "    remove_mean (bool): If True, subtract the parcel-wise mean\n",
        "\n",
        "  Returns\n",
        "    ts (n_parcel x n_timepoint array): Array of BOLD data values\n",
        "\n",
        "  \"\"\"\n",
        "  bold_path = os.path.join(dir, \"subjects\", str(subject), \"timeseries\")\n",
        "  bold_file = f\"bold{bold_run}_Atlas_MSMAll_Glasser360Cortical.npy\"\n",
        "  ts = np.load(os.path.join(bold_path, bold_file))\n",
        "  if remove_mean:\n",
        "    ts -= ts.mean(axis=1, keepdims=True)\n",
        "  return ts\n",
        "\n",
        "\n",
        "def load_evs(subject, name, condition, dir):\n",
        "  \"\"\"Load EV (explanatory variable) data for one task condition.\n",
        "\n",
        "  Args:\n",
        "    subject (int): 0-based subject ID to load\n",
        "    name (str) : Name of task\n",
        "    condition (str) : Name of condition\n",
        "    dir (str) : data directory\n",
        "\n",
        "  Returns\n",
        "    evs (list of dicts): A dictionary with the onset, duration, and amplitude\n",
        "      of the condition for each run.\n",
        "\n",
        "  \"\"\"\n",
        "  evs = []\n",
        "  for id in get_image_ids(name):\n",
        "    task_key = BOLD_NAMES[id - 1]\n",
        "    ev_file = os.path.join(dir, \"subjects\", str(subject), \"EVs\",\n",
        "                           task_key, f\"{condition}.txt\")\n",
        "    ev_array = np.loadtxt(ev_file, ndmin=2, unpack=True)\n",
        "    ev = dict(zip([\"onset\", \"duration\", \"amplitude\"], ev_array))\n",
        "    evs.append(ev)\n",
        "  return evs"
      ],
      "metadata": {
        "id": "vWZfZEJikqED"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print total count of subject ids that do not have 'tfMRI_EMOTION_LR' and 'tfMRI_EMOTION_RL'\n",
        "\n",
        "emotion_lr_rl_present = set()\n",
        "for subject_id_dir in os.listdir(emotions_dir):\n",
        "  subject_id_path = os.path.join(emotions_dir, subject_id_dir)\n",
        "  if os.path.isdir(subject_id_path) and os.path.isdir(os.path.join(subject_id_path, \"EVs\")):\n",
        "    evs_dir = os.path.join(subject_id_path, \"EVs\")\n",
        "    emotion_lr_path = os.path.join(evs_dir, \"tfMRI_EMOTION_LR\")\n",
        "    emotion_rl_path = os.path.join(evs_dir, \"tfMRI_EMOTION_RL\")\n",
        "    if os.path.isdir(emotion_lr_path) or os.path.isdir(emotion_rl_path):\n",
        "      emotion_lr_rl_present.add(subject_id_dir)\n",
        "\n",
        "all_subject_ids = set([d for d in os.listdir(emotions_dir) if os.path.isdir(os.path.join(emotions_dir, d)) and os.path.isdir(os.path.join(emotions_dir, d, \"EVs\"))])\n",
        "\n",
        "subjects_without_emotion_lr_rl = all_subject_ids - emotion_lr_rl_present\n",
        "\n",
        "print(f\"Total count of subject IDs without 'tfMRI_EMOTION_LR' and 'tfMRI_EMOTION_RL': {len(subjects_without_emotion_lr_rl)}\")"
      ],
      "metadata": {
        "id": "3VcSuYvfpXJD",
        "outputId": "0d2eb729-63e8-435f-efad-0e2b3b6e266c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total count of subject IDs without 'tfMRI_EMOTION_LR' and 'tfMRI_EMOTION_RL': 0\n"
          ]
        }
      ]
    }
  ]
}